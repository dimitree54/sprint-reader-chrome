# Test Design: Story 1.4 - Create BrowserApiService

**Story ID:** 1.4
**Feature:** Create BrowserApiService
**Test Design Date:** 2025-09-26
**Test Designer:** Quinn (QA Agent)

## Test Strategy Overview

This test design provides comprehensive validation for the BrowserApiService implementation, focusing on critical infrastructure testing without fallbacks. The strategy prioritizes fail-fast detection of any regressions while ensuring the service correctly abstracts browser API interactions.

## Test Categories

### 1. Unit Tests (Vitest)

#### 1.1 Core Service Functionality

**Test Suite:** `src/core/browser-api.service.spec.ts`

**Existing Coverage:**
- ✅ Chrome API wrapping with promise resolution
- ✅ Error handling with chrome.runtime.lastError
- ✅ Singleton pattern instantiation

**Required Additional Coverage:**

```typescript
// Storage Operations
describe('Storage API', () => {
  it('should get storage items successfully')
  it('should set storage items successfully')
  it('should handle storage errors properly')
  it('should return empty object when storage unavailable')
})

// Window Management
describe('Window Management', () => {
  it('should create window with correct parameters')
  it('should update window successfully')
  it('should expose onWindowRemoved event handler')
  it('should handle window creation errors')
})

// Tab Management
describe('Tab Management', () => {
  it('should create tab with specified properties')
  it('should query tabs with filters')
  it('should send messages to specific tab')
  it('should handle tab operation errors')
})

// Context Menu Operations
describe('Context Menu API', () => {
  it('should remove all context menus')
  it('should create context menu items')
  it('should expose onClicked event handler')
  it('should handle context menu errors')
})

// Browser Detection
describe('Browser Detection', () => {
  it('should prefer native browser API over Chrome')
  it('should adapt Chrome API when browser unavailable')
  it('should throw error when no browser API available')
})
```

#### 1.2 ChromeAdapter Testing

**Test Suite:** `src/core/chrome-adapter.spec.ts` (to be created)

```typescript
describe('ChromeAdapter', () => {
  describe('Promise Wrapping', () => {
    it('should convert callback-based APIs to promises')
    it('should handle chrome.runtime.lastError correctly')
    it('should propagate callback exceptions')
    it('should handle synchronous exceptions')
  })

  describe('Message Handling', () => {
    it('should handle sendMessage with various argument patterns')
    it('should normalize sendMessage arguments correctly')
    it('should support extensionId parameter')
    it('should support options parameter')
  })

  describe('API Adaptation', () => {
    it('should adapt all required Chrome API surfaces')
    it('should maintain method signatures')
    it('should preserve event handlers')
  })
})
```

### 2. Integration Tests

#### 2.1 Browser API Integration

**Test File:** `test/integration/browser-api.integration.spec.ts`

These tests validate the service against actual browser APIs in a controlled environment:

```typescript
describe('BrowserApiService Integration', () => {
  describe('Runtime Messaging', () => {
    it('should send messages between background and content scripts')
    it('should handle message responses correctly')
    it('should fail fast on messaging errors')
  })

  describe('Storage Persistence', () => {
    it('should persist and retrieve extension settings')
    it('should handle storage quota limitations')
    it('should maintain data consistency')
  })

  describe('Window Lifecycle', () => {
    it('should create reader window with correct properties')
    it('should update window state successfully')
    it('should handle window destruction events')
  })
})
```

### 3. Cross-Platform Compatibility Tests

#### 3.1 Chrome vs Firefox Validation

**Test Suite:** Platform-specific test runs

```bash
# Chrome-specific testing
npm run test:chrome -- --browser-api=chrome

# Firefox-specific testing
npm run test:firefox -- --browser-api=firefox
```

**Test Coverage:**
- API availability differences
- Error handling variations
- Event handler compatibility
- Manifest permissions validation

### 4. Existing Test Validation

#### 4.1 Playwright End-to-End Tests

**Command:** `npm test`

**Critical Test Scenarios:**
- Reader window creation and functionality
- Optimal letter highlighting
- Text preprocessing capabilities
- Playback control interactions
- OpenAI integration (requires real API key)

**Validation Points:**
- Zero regression in existing functionality
- All user workflows remain intact
- Extension installation and activation
- Cross-context messaging still functional

### 5. Manual Testing Checklist

#### 5.1 Extension Core Functionality

**Pre-Test Setup:**
- Clean extension installation
- Configure OpenAI API key if testing streaming
- Test on Chrome, Firefox (Safari if applicable)

**Test Cases:**

```markdown
## Installation & Startup
- [ ] Extension installs without errors
- [ ] Background service worker starts successfully
- [ ] Extension icon appears in browser toolbar
- [ ] Context menu items are created properly

## Reader Functionality
- [ ] Text selection triggers reader window
- [ ] Keyboard shortcut (Alt+Shift+R) works
- [ ] Reader window opens with correct dimensions
- [ ] Playback controls function correctly
- [ ] WPM slider adjusts speed appropriately
- [ ] Theme toggle switches light/dark mode

## Settings & Storage
- [ ] Settings page opens from popup
- [ ] API key can be saved and retrieved
- [ ] Preferences persist across sessions
- [ ] Clear API key function works

## Cross-Context Communication
- [ ] Background ↔ Content script messaging
- [ ] Background ↔ Reader window messaging
- [ ] Background ↔ Popup messaging
- [ ] Background ↔ Settings messaging
```

## Validation Commands

### 5.1 Required Validation Sequence

Execute in this exact order with **no fallbacks**:

```bash
# 1. Code quality validation
npm run lint           # Must pass - no warnings allowed
npm run typecheck      # Must pass - no type errors allowed

# 2. Build validation
npm run build:chrome   # Must succeed - no build errors allowed

# 3. Test execution
npm run test          # Must pass - requires real OPENAI_API_KEY
```

### 5.2 Failure Handling Protocol

**Lint Failures:**
- ❌ FAIL: Report exact linting violations
- ❌ FAIL: Identify root cause in code changes
- ❌ NO FALLBACKS: Fix issues, don't ignore/suppress

**TypeScript Failures:**
- ❌ FAIL: Report type errors with file:line references
- ❌ FAIL: Analyze type safety violations
- ❌ NO FALLBACKS: Resolve types, don't use 'any'

**Build Failures:**
- ❌ FAIL: Report build errors with context
- ❌ FAIL: Identify missing dependencies or configuration issues
- ❌ NO FALLBACKS: Fix root cause, don't skip browser targets

**Test Failures:**
- ❌ FAIL: Report failing test names and error details
- ❌ FAIL: Identify regression root cause
- ❌ NO FALLBACKS: Fix code issues, don't skip/mock tests

## OpenAI Integration Testing

### 6.1 Real API Key Requirement

**Environment Setup:**
```bash
export OPENAI_API_KEY="sk-..."  # Real key required
npm test                        # No mocks/fallbacks allowed
```

**Test Coverage:**
- Streaming text preprocessing
- Real-time progress updates
- Error handling with actual API
- Network timeout scenarios
- API quota/rate limit handling

**Failure Scenarios:**
- Invalid API key → Must fail fast with clear error
- Network issues → Must fail fast, no silent fallbacks
- API errors → Must propagate error, no default responses

## Quality Gates

### 7.1 Pre-Release Gates

**Mandatory Requirements:**
- [ ] All unit tests pass (100% success rate)
- [ ] All integration tests pass
- [ ] All Playwright tests pass with real API key
- [ ] Manual testing checklist 100% complete
- [ ] Cross-browser compatibility verified
- [ ] Performance benchmarks within acceptable ranges

### 7.2 Regression Detection

**Critical Metrics:**
- Extension load time < 200ms
- Reader window creation < 500ms
- Text processing accuracy 100%
- API error rate < 1%
- Memory usage stable (no leaks)

**Monitoring Points:**
- Browser console errors (zero allowed)
- Extension error logs (zero critical errors)
- User workflow completion rates
- Cross-platform functionality parity

## Test Data Requirements

### 8.1 Text Samples

**Required Test Content:**
- Plain text (various lengths)
- HTML with complex formatting
- Unicode/international characters
- Very long articles (>50k words)
- Empty/minimal content edge cases

### 8.2 Configuration Variants

**API Configurations:**
- Valid OpenAI API key
- Invalid/expired API key
- No API key configured
- Network connectivity issues

**Browser Configurations:**
- Chrome (latest stable)
- Firefox (latest stable)
- Safari (if supported)
- Various permission states

## Success Criteria

### 9.1 Definition of Done

**All the following must be true:**
1. ✅ All validation commands pass without errors
2. ✅ Zero regression in existing functionality
3. ✅ BrowserApiService successfully abstracts all browser APIs
4. ✅ Cross-platform compatibility maintained
5. ✅ Manual testing checklist 100% complete
6. ✅ Performance within acceptable ranges
7. ✅ No silent failures or hidden errors

### 9.2 Failure Criteria

**Any of the following triggers story failure:**
1. ❌ Any validation command fails
2. ❌ Any existing test regresses
3. ❌ Extension functionality degraded
4. ❌ Browser API abstraction incomplete
5. ❌ Performance significantly degraded
6. ❌ Silent failures or error suppression detected

**Story cannot be marked complete until all failure criteria are resolved with root cause fixes, not workarounds.**